{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a4bc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca00e85",
   "metadata": {},
   "source": [
    "# While Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9665253",
   "metadata": {},
   "source": [
    "### wrong code\n",
    "```python\n",
    "while not (next_page == None):\n",
    "    response = requests.get(swapi_people_df['next'])\n",
    "    data = response.json()\n",
    "\n",
    "    next_page = data['next']\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(data['results'])]).reset_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca13459",
   "metadata": {},
   "source": [
    "### alternate version\n",
    "```python\n",
    "url = 'https://swapi.dev/api/people/'\n",
    "people = []\n",
    "while url:\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    people.extend(data['results'])\n",
    "    url = data['next']\n",
    "\n",
    "df = pd.DataFrame(people)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c2618",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60dfed",
   "metadata": {},
   "source": [
    "Create a new local git repository and remote repository on github named time-series-exercises. Save this work for this module in your time-series-exercises repo.\n",
    "\n",
    "The end result of this exercise should be a file named acquire.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c7e9c",
   "metadata": {},
   "source": [
    "### 1. Using the code from the lesson as a guide and the REST API from https://swapi.dev/ as we did in the lesson, create a dataframe named people that has all of the data for people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "254eb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Star Wars API Root Directory Setup\n",
    "# root url (table of contents)\n",
    "root_url = 'https://swapi.dev/api/'\n",
    "\n",
    "# saving response to save as .json\n",
    "root_response = requests.get(root_url)\n",
    "\n",
    "# converting to .json\n",
    "root_response_data = root_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e4848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing starwars api for people\n",
    "people_df = pd.DataFrame()\n",
    "people_next_page = root_response_data[\"people\"]\n",
    "\n",
    "while people_next_page is not None:\n",
    "    people_response = requests.get(people_next_page)\n",
    "    people_data = people_response.json()\n",
    "    people_df = pd.concat([people_df, pd.DataFrame(people_data['results'])], ignore_index=True)\n",
    "    people_next_page = people_data['next']\n",
    "\n",
    "people_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe594c50",
   "metadata": {},
   "source": [
    "### 2. Do the same thing, but for planets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f827acd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets_df = pd.DataFrame()\n",
    "people_next_page = root_response_data[\"planets\"]\n",
    "\n",
    "while planets_next_page is not None:\n",
    "    planets_response = requests.get(planets_next_page)\n",
    "    planets_data = planets_response.json()\n",
    "    planets_df = pd.concat([planets_df, pd.DataFrame(planets_data['results'])], ignore_index=True)\n",
    "    planets_next_page = planets_data['next']\n",
    "\n",
    "planets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93750ae",
   "metadata": {},
   "source": [
    "### 3. Extract the data for starships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785e3583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starships_df = pd.DataFrame()\n",
    "starships_next_page = root_response_data[\"starships\"]\n",
    "\n",
    "while starships_next_page is not None:\n",
    "    starships_response = requests.get(starships_next_page)\n",
    "    starships_data = starships_response.json()\n",
    "    starships_df = pd.concat([starships_df, pd.DataFrame(starships_data['results'])], ignore_index=True)\n",
    "    starships_next_page = starships_data['next']\n",
    "\n",
    "starships_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e4a3de",
   "metadata": {},
   "source": [
    "### 4. Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f475689",
   "metadata": {},
   "source": [
    "`df.to_csv(,drop=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af830c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File people.csv already exists.\n"
     ]
    }
   ],
   "source": [
    "filename = 'people.csv'\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    people_df.to_csv(filename, index=False)\n",
    "    print(f\"Saving {filename}...\")\n",
    "else:\n",
    "    print(f\"File {filename} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe1da615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving planets.csv...\n"
     ]
    }
   ],
   "source": [
    "filename = 'planets.csv'\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    planets_df.to_csv(filename, index=False)\n",
    "    print(f\"Saving {filename}...\")\n",
    "else:\n",
    "    print(f\"File {filename} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3da9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving starships.csv...\n"
     ]
    }
   ],
   "source": [
    "filename = 'starships.csv'\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    starships_df.to_csv(filename, index=False)\n",
    "    print(f\"Saving {filename}...\")\n",
    "else:\n",
    "    print(f\"File {filename} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2cfef4",
   "metadata": {},
   "source": [
    "### 5. Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e10bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df[\"Type\"] = \"People\"\n",
    "planets_df[\"Type\"] = \"Planet\"\n",
    "starships_df[\"Type\"] = \"Starship\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cac2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_df = pd.concat([people_df, planets_df, starships_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "658ecb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People      82\n",
       "Planet      60\n",
       "Starship    36\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giant_df[\"Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88601d14",
   "metadata": {},
   "source": [
    "### 6. Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490220a",
   "metadata": {},
   "source": [
    "`df.read_csv(,drop=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fecebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv\"\n",
    "energy_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c2570d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving opsd_germany_daily.csv...\n"
     ]
    }
   ],
   "source": [
    "filename = 'opsd_germany_daily.csv'\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    energy_df.to_csv(filename, index=False)\n",
    "    print(f\"Saving {filename}...\")\n",
    "else:\n",
    "    print(f\"File {filename} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba512b1",
   "metadata": {},
   "source": [
    "### 7. Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d77f08",
   "metadata": {},
   "source": [
    "```python\n",
    "get_people()\n",
    "get_planets()\n",
    "get_starships()\n",
    "get_all_starwars()\n",
    "get_energy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37acf017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_star_wars_api_url(info):\n",
    "    # Star Wars API Root Directory Setup\n",
    "    # root url (table of contents)\n",
    "    root_url = 'https://swapi.dev/api/'\n",
    "\n",
    "    # saving response to save as .json\n",
    "    root_response = requests.get(root_url)\n",
    "\n",
    "    # converting to .json\n",
    "    root_response_data = root_response.json()\n",
    "    \n",
    "    return root_response_data[info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86e97f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_people(save=True):\n",
    "    people_df = pd.DataFrame()\n",
    "    people_next_page = get_star_wars_api_url(\"people\")\n",
    "\n",
    "    while people_next_page is not None:\n",
    "        people_response = requests.get(people_next_page)\n",
    "        people_data = people_response.json()\n",
    "        people_df = pd.concat([people_df, pd.DataFrame(people_data['results'])], ignore_index=True)\n",
    "        people_next_page = people_data['next']\n",
    "    \n",
    "    if save:\n",
    "        # save to csv if option selected\n",
    "        filename = 'people.csv'\n",
    "\n",
    "        if not os.path.exists(filename):\n",
    "            people_df.to_csv(filename, index=False)\n",
    "            print(f\"Saving {filename}...\")\n",
    "        else:\n",
    "            print(f\"File {filename} already exists.\")\n",
    "            \n",
    "    return people_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "631f7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_planets(save=True):\n",
    "    planets_df = pd.DataFrame()\n",
    "    planets_next_page = get_star_wars_api_url(\"planets\")\n",
    "\n",
    "    while planets_next_page is not None:\n",
    "        planets_response = requests.get(planets_next_page)\n",
    "        planets_data = planets_response.json()\n",
    "        planets_df = pd.concat([planets_df, pd.DataFrame(planets_data['results'])], ignore_index=True)\n",
    "        planets_next_page = planets_data['next']\n",
    "       \n",
    "    if save:\n",
    "        # save to csv if option selected\n",
    "        filename = 'planets.csv'\n",
    "\n",
    "        if not os.path.exists(filename):\n",
    "            planets_df.to_csv(filename, index=False)\n",
    "            print(f\"Saving {filename}...\")\n",
    "        else:\n",
    "            print(f\"File {filename} already exists.\")\n",
    "    return planets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "821fea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starships(save=True):\n",
    "    starships_df = pd.DataFrame()\n",
    "    starships_next_page = get_star_wars_api_url(\"starships\")\n",
    "\n",
    "    while starships_next_page is not None:\n",
    "        starships_response = requests.get(starships_next_page)\n",
    "        starships_data = starships_response.json()\n",
    "        starships_df = pd.concat([starships_df, pd.DataFrame(starships_data['results'])], ignore_index=True)\n",
    "        starships_next_page = starships_data['next']\n",
    "    \n",
    "    if save:\n",
    "        # save to csv if option selected\n",
    "        filename = 'starships.csv'\n",
    "\n",
    "        if not os.path.exists(filename):\n",
    "            starships_df.to_csv(filename, index=False)\n",
    "            print(f\"Saving {filename}...\")\n",
    "        else:\n",
    "            print(f\"File {filename} already exists.\")\n",
    "\n",
    "    return starships_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f361e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_starwars(save=True):\n",
    "    # 3 temporary dataframes to hold each type of data\n",
    "    people_df = get_people(save)\n",
    "    planets_df = get_planets(save)\n",
    "    starships_df = get_starships(save)\n",
    "    \n",
    "    # columns for sorting ability\n",
    "    people_df[\"Type\"] = \"People\"\n",
    "    planets_df[\"Type\"] = \"Planet\"\n",
    "    starships_df[\"Type\"] = \"Starship\"\n",
    "    \n",
    "    #concatenate all 3 into one giant DataFrame\n",
    "    \n",
    "    return pd.concat([people_df, planets_df, starships_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb43e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy():\n",
    "    url = \"https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv\"\n",
    "    energy_df = pd.read_csv(url)\n",
    "    \n",
    "    filename = 'opsd_germany_daily.csv'\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        energy_df.to_csv(filename, index=False)\n",
    "        print(f\"Saving {filename}...\")\n",
    "    else:\n",
    "        print(f\"File {filename} already exists.\")\n",
    "    return energy_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
